{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing is listening on port 10000 - will attempt to launch Minecraft from a new terminal.\n",
      "Giving Minecraft some time to launch... \n",
      ". . . . . . . . . . . . . . . . . . . . . . . . ok\n",
      "C:\\Users\\User\\Desktop\\Malmo\\MalmoPlatform\\Schemas\n"
     ]
    }
   ],
   "source": [
    "import malmo.minecraftbootstrap; malmo.minecraftbootstrap.launch_minecraft()\n",
    "malmo.minecraftbootstrap.set_malmo_xsd_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from future import standard_library\n",
    "standard_library.install_aliases()\n",
    "from builtins import range\n",
    "from builtins import object\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# Microsoft Malmo API\n",
    "import malmo.MalmoPython as MalmoPython\n",
    "\n",
    "# Check Tkinter version on your pc.\n",
    "if sys.version_info[0] == 2:  \n",
    "    import Tkinter as tk\n",
    "else:\n",
    "    import tkinter as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent's action\n",
    "agent_actions = [\"move 1\", \"move -1\", \"turn 1\", \"turn -1\"]\n",
    "\n",
    "# Appoint value to epsilon.\n",
    "epsilon = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleQL(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epsilon = epsilon\n",
    "        self.count = 0\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if False: \n",
    "            self.logger.setLevel(logging.DEBUG)\n",
    "        else:\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "        self.logger.handlers = []\n",
    "        self.logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "        self.actions = agent_actions\n",
    "        self.q_table = {}\n",
    "        self.canvas = None\n",
    "        self.root = None\n",
    "        \n",
    "    def count_action(self):\n",
    "        return self.count\n",
    "    \n",
    "    def resetcount_action(self):\n",
    "        self.count = 0\n",
    "        return self.count\n",
    "\n",
    "    def updateQTable( self, reward, current_state ):\n",
    "        \n",
    "        # retrieve the old action value from the Q-table (indexed by the previous state and the previous action)\n",
    "        old_q = self.q_table[self.prev_s][self.prev_a]\n",
    "        \n",
    "        new_q = old_q\n",
    "        \n",
    "        # assign the new action value to the Q-table\n",
    "        self.q_table[self.prev_s][self.prev_a] = new_q\n",
    "        \n",
    "    def updateQTableFromTerminatingState( self, reward ):\n",
    "        \n",
    "        # retrieve the old action value from the Q-table (indexed by the previous state and the previous action)\n",
    "        old_q = self.q_table[self.prev_s][self.prev_a]\n",
    "        \n",
    "        new_q = old_q\n",
    "        \n",
    "        # assign the new action value to the Q-table\n",
    "        self.q_table[self.prev_s][self.prev_a] = new_q\n",
    "        \n",
    "    def act(self, world_state, agent_host, current_r ):\n",
    "        \n",
    "        obs_text = world_state.observations[-1].text\n",
    "        obs = json.loads(obs_text) # most recent observation\n",
    "        self.logger.debug(obs)\n",
    "        if not u'XPos' in obs or not u'ZPos' in obs:\n",
    "            self.logger.error(\"Incomplete observation received: %s\" % obs_text)\n",
    "            return 0\n",
    "        current_s = \"%d:%d\" % (int(obs[u'XPos']), int(obs[u'ZPos']))\n",
    "        self.logger.debug(\"State: %s (x = %.2f, z = %.2f)\" % (current_s, float(obs[u'XPos']), float(obs[u'ZPos'])))\n",
    "        if current_s not in self.q_table:\n",
    "            self.q_table[current_s] = ([0] * len(self.actions))\n",
    "\n",
    "        # update Q values\n",
    "        if self.prev_s is not None and self.prev_a is not None:\n",
    "            self.updateQTable( current_r, current_s )\n",
    "\n",
    "        self.drawQ( curr_x = int(obs[u'XPos']), curr_y = int(obs[u'ZPos']) )\n",
    "\n",
    "        # select the next action\n",
    "        rnd = random.random()\n",
    "        if rnd < self.epsilon:\n",
    "            a = random.randint(0, len(self.actions) - 1)\n",
    "            self.actions[a]\n",
    "        else:\n",
    "            m = max(self.q_table[current_s])\n",
    "            self.logger.debug(\"Current values: %s\" % \",\".join(str(x) for x in self.q_table[current_s]))\n",
    "            l = list()\n",
    "            for x in range(0, len(self.actions)):\n",
    "                if self.q_table[current_s][x] == m:\n",
    "                    l.append(x)\n",
    "            y = random.randint(0, len(l)-1)\n",
    "            a = l[y]\n",
    "            self.actions[a]\n",
    "            \n",
    "        # try to send the selected action, only update prev_s if this succeeds\n",
    "        try:\n",
    "            agent_host.sendCommand(self.actions[a])\n",
    "            self.prev_s = current_s\n",
    "            self.prev_a = a\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            self.logger.error(\"Failed to send command: %s\" % e)\n",
    "        \n",
    "        self.count += 1\n",
    "        return current_r\n",
    "\n",
    "    def run(self, agent_host):\n",
    "\n",
    "        total_reward = 0\n",
    "        \n",
    "        self.prev_s = None\n",
    "        self.prev_a = None\n",
    "        \n",
    "        is_first_action = True\n",
    "        \n",
    "        # main loop:\n",
    "        world_state = agent_host.getWorldState()\n",
    "        while world_state.is_mission_running:\n",
    "\n",
    "            current_r = 0\n",
    "            \n",
    "            if is_first_action:\n",
    "                # wait until have received a valid observation\n",
    "                while True:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                    for reward in world_state.rewards:\n",
    "                        current_r += reward.getValue()\n",
    "                    if world_state.is_mission_running and len(world_state.observations)>0 and not world_state.observations[-1].text==\"{}\":\n",
    "                        total_reward += self.act(world_state, agent_host, current_r)\n",
    "                        break\n",
    "                    if not world_state.is_mission_running:\n",
    "                        break\n",
    "                is_first_action = False\n",
    "            else:\n",
    "                # wait for non-zero reward\n",
    "                while world_state.is_mission_running and current_r == 0:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                    for reward in world_state.rewards:\n",
    "                        current_r += reward.getValue()\n",
    "                # allow time to stabilise after action\n",
    "                while True:\n",
    "                    time.sleep(0.1)\n",
    "                    world_state = agent_host.getWorldState()\n",
    "                    for error in world_state.errors:\n",
    "                        self.logger.error(\"Error: %s\" % error.text)\n",
    "                    for reward in world_state.rewards:\n",
    "                        current_r += reward.getValue()\n",
    "                    if world_state.is_mission_running and len(world_state.observations)>0 and not world_state.observations[-1].text==\"{}\":\n",
    "                        total_reward += self.act(world_state, agent_host, current_r)\n",
    "                        break\n",
    "                    if not world_state.is_mission_running:\n",
    "                        break\n",
    "\n",
    "        # process final reward\n",
    "        self.logger.debug(\"Final reward: %d\" % current_r)\n",
    "        total_reward += current_r\n",
    "\n",
    "        # update Q values\n",
    "        if self.prev_s is not None and self.prev_a is not None:\n",
    "            self.updateQTableFromTerminatingState( current_r ) \n",
    "            \n",
    "        self.drawQ()\n",
    "    \n",
    "        return total_reward\n",
    "        \n",
    "    def drawQ( self, curr_x=None, curr_y=None ):\n",
    "        scale = 22\n",
    "        world_x = 35\n",
    "        world_y = 35\n",
    "        if self.canvas is None or self.root is None:\n",
    "            self.root = tk.Tk()\n",
    "            self.root.wm_title(\"Q-table\")\n",
    "            self.canvas = tk.Canvas(self.root, width=world_x*scale, height=world_y*scale, borderwidth=0, highlightthickness=0, bg=\"black\")\n",
    "            self.canvas.grid()\n",
    "            self.root.update()\n",
    "        self.canvas.delete(\"all\")\n",
    "        action_inset = 0.1\n",
    "        action_radius = 0.1\n",
    "        curr_radius = 0.2\n",
    "        action_positions = [ ( 0.5, action_inset ), ( 0.5, 1-action_inset ), ( action_inset, 0.5 ), ( 1-action_inset, 0.5 ) ]\n",
    "        min_value = -20\n",
    "        max_value = 20\n",
    "        for x in range(world_x):\n",
    "            for y in range(world_y):\n",
    "                s = \"%d:%d\" % (x,y)\n",
    "                self.canvas.create_rectangle( x*scale, y*scale, (x+1)*scale, (y+1)*scale, outline=\"#fff\", fill=\"#000\")\n",
    "                for action in range(4):\n",
    "                    if not s in self.q_table:\n",
    "                        continue\n",
    "                    value = self.q_table[s][action]\n",
    "                    color = int( 255 * ( value - min_value ) / ( max_value - min_value ))\n",
    "                    color = max( min( color, 255 ), 0 )\n",
    "                    color_string = '#%02x%02x%02x' % (255-color, color, 0)\n",
    "                    self.canvas.create_oval( (x + action_positions[action][0] - action_radius ) *scale,\n",
    "                                             (y + action_positions[action][1] - action_radius ) *scale,\n",
    "                                             (x + action_positions[action][0] + action_radius ) *scale,\n",
    "                                             (y + action_positions[action][1] + action_radius ) *scale, \n",
    "                                             outline=color_string, fill=color_string )\n",
    "        if curr_x is not None and curr_y is not None:\n",
    "            self.canvas.create_oval( (curr_x + 0.5 - curr_radius ) * scale, \n",
    "                                     (curr_y + 0.5 - curr_radius ) * scale, \n",
    "                                     (curr_x + 0.5 + curr_radius ) * scale, \n",
    "                                     (curr_y + 0.5 + curr_radius ) * scale, \n",
    "                                     outline=\"#fff\", fill=\"#fff\" )\n",
    "        self.root.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Caught std::exception: unrecognised option '-f'\n",
      "\n",
      "Malmo version: 0.36.0\n",
      "\n",
      "Allowed options:\n",
      "  -h [ --help ]         show description of allowed options\n",
      "  --test                run this as an integration test\n",
      "\n",
      "\n",
      "Loading mission from ./maze2.xml\n",
      "\n",
      "Repeat 1 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-772\n",
      "Total time trained: 300.49804615974426 seconds\n",
      "Number of actions performed: 773\n",
      "\n",
      "Repeat 2 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:-176\n",
      "Total time trained: 300.302921295166 seconds\n",
      "Number of actions performed: 676\n",
      "\n",
      "Repeat 3 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-108\n",
      "Total time trained: 300.6986391544342 seconds\n",
      "Number of actions performed: 609\n",
      "\n",
      "Repeat 4 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:-277\n",
      "Total time trained: 144.77811121940613 seconds\n",
      "Number of actions performed: 277\n",
      "\n",
      "Repeat 5 of 30\n",
      "Waiting for the mission to start ...\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:1702\n",
      "Total time trained: 172.47680950164795 seconds\n",
      "Number of actions performed: 299\n",
      "\n",
      "Repeat 6 of 30\n",
      "Waiting for the mission to start .....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:-495\n",
      "Total time trained: 300.6932575702667 seconds\n",
      "Number of actions performed: 495\n",
      "\n",
      "Repeat 7 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:530\n",
      "Total time trained: 300.74001121520996 seconds\n",
      "Number of actions performed: 471\n",
      "\n",
      "Repeat 8 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:41\n",
      "Total time trained: 301.0053925514221 seconds\n",
      "Number of actions performed: 460\n",
      "\n",
      "Repeat 9 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:44\n",
      "Total time trained: 300.7211890220642 seconds\n",
      "Number of actions performed: 457\n",
      "\n",
      "Repeat 10 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:347\n",
      "Total time trained: 105.7144706249237 seconds\n",
      "Number of actions performed: 154\n",
      "\n",
      "Repeat 11 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-224\n",
      "Total time trained: 158.29303765296936 seconds\n",
      "Number of actions performed: 225\n",
      "\n",
      "Repeat 12 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:-422\n",
      "Total time trained: 300.74240899086 seconds\n",
      "Number of actions performed: 422\n",
      "\n",
      "Repeat 13 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-424\n",
      "Total time trained: 301.2614862918854 seconds\n",
      "Number of actions performed: 425\n",
      "\n",
      "Repeat 14 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:89\n",
      "Total time trained: 300.8180320262909 seconds\n",
      "Number of actions performed: 412\n",
      "\n",
      "Repeat 15 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:10184\n",
      "Total time trained: 228.9418158531189 seconds\n",
      "Number of actions performed: 317\n",
      "\n",
      "Repeat 16 of 30\n",
      "Waiting for the mission to start .....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:93\n",
      "Total time trained: 300.8599307537079 seconds\n",
      "Number of actions performed: 408\n",
      "\n",
      "Repeat 17 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:1368\n",
      "Total time trained: 96.95943212509155 seconds\n",
      "Number of actions performed: 132\n",
      "\n",
      "Repeat 18 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:607\n",
      "Total time trained: 301.0538830757141 seconds\n",
      "Number of actions performed: 394\n",
      "\n",
      "Repeat 19 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-384\n",
      "Total time trained: 301.1549882888794 seconds\n",
      "Number of actions performed: 385\n",
      "\n",
      "Repeat 20 of 30\n",
      "Waiting for the mission to start .....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:116\n",
      "Total time trained: 300.6224904060364 seconds\n",
      "Number of actions performed: 384\n",
      "\n",
      "Repeat 21 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:10436\n",
      "Total time trained: 51.492802143096924 seconds\n",
      "Number of actions performed: 65\n",
      "\n",
      "Repeat 22 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Reward obtained:-375\n",
      "Total time trained: 300.7551589012146 seconds\n",
      "Number of actions performed: 375\n",
      "\n",
      "Repeat 23 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-138\n",
      "Total time trained: 109.68660545349121 seconds\n",
      "Number of actions performed: 139\n",
      "\n",
      "Repeat 24 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-347\n",
      "Total time trained: 301.4594945907593 seconds\n",
      "Number of actions performed: 348\n",
      "\n",
      "Repeat 25 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-346\n",
      "Total time trained: 300.81167221069336 seconds\n",
      "Number of actions performed: 347\n",
      "\n",
      "Repeat 26 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:123\n",
      "Total time trained: 301.16865253448486 seconds\n",
      "Number of actions performed: 378\n",
      "\n",
      "Repeat 27 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:10311\n",
      "Total time trained: 156.3373143672943 seconds\n",
      "Number of actions performed: 190\n",
      "\n",
      "Repeat 28 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:-363\n",
      "Total time trained: 300.8604073524475 seconds\n",
      "Number of actions performed: 364\n",
      "\n",
      "Repeat 29 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:1638\n",
      "Total time trained: 301.48347663879395 seconds\n",
      "Number of actions performed: 363\n",
      "\n",
      "Repeat 30 of 30\n",
      "Waiting for the mission to start ....\n",
      "Mission started \n",
      "--------------------------------\n",
      "Error: AgentHost::sendCommand : commands connection is not open. Is the mission running?\n",
      "Reward obtained:9863\n",
      "Total time trained: 115.54245090484619 seconds\n",
      "Number of actions performed: 138\n",
      "\n",
      "Done.\n",
      "Cumulative rewards for all 30 runs:\n",
      "[-772.0, -176.0, -108.0, -277.0, 1702.0, -495.0, 530.0, 41.0, 44.0, 347.0, -224.0, -422.0, -424.0, 89.0, 10184.0, 93.0, 1368.0, 607.0, -384.0, 116.0, 10436.0, -375.0, -138.0, -347.0, -346.0, 123.0, 10311.0, -363.0, 1638.0, 9863.0]\n",
      "Average reward: 1421.3666666666666\n",
      "Total time used for 30 trials: 7372.269910335541 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time_all_trials = time.time()\n",
    "results_df = []\n",
    "cumulative_rewards = []\n",
    "\n",
    "agent = SimpleQL()\n",
    "agent_host = MalmoPython.AgentHost()\n",
    "\n",
    "try:\n",
    "    agent_host.parse( sys.argv )\n",
    "except RuntimeError as e:\n",
    "    print('ERROR:',e)\n",
    "    print(agent_host.getUsage())\n",
    "    exit(1)\n",
    "if agent_host.receivedArgument(\"help\"):\n",
    "    print(agent_host.getUsage())\n",
    "    exit(0)\n",
    "\n",
    "mission_file = './maze2.xml'\n",
    "with open(mission_file, 'r') as f:\n",
    "    print(\"Loading mission from %s\" % mission_file)\n",
    "    mission_xml = f.read()\n",
    "    my_mission = MalmoPython.MissionSpec(mission_xml, True)\n",
    "\n",
    "    \n",
    "agent_host.setObservationsPolicy(MalmoPython.ObservationsPolicy.LATEST_OBSERVATION_ONLY)\n",
    "agent_host.setVideoPolicy(MalmoPython.VideoPolicy.LATEST_FRAME_ONLY)\n",
    "my_mission_record = MalmoPython.MissionRecordSpec()\n",
    "my_mission.requestVideo(800, 500)\n",
    "my_mission.setViewpoint(0)\n",
    "\n",
    "my_clients = MalmoPython.ClientPool()\n",
    "my_clients.add(MalmoPython.ClientInfo('127.0.0.1', 10000)) # add Minecraft machines here as available\n",
    "agentID = 0\n",
    "expID = 'Simple Q-Learning'\n",
    "\n",
    "max_retries = 3\n",
    "\n",
    "if agent_host.receivedArgument(\"test\"):\n",
    "    num_repeats = 1\n",
    "else:\n",
    "    num_repeats = 30\n",
    "\n",
    "for i in range(num_repeats):\n",
    "    \n",
    "    print()\n",
    "    print('Repeat %d of %d' % (i+1, num_repeats ))\n",
    "    \n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            agent_host.startMission(my_mission, my_clients, my_mission_record, agentID, \"%s-%d\" % (expID, i))\n",
    "            break\n",
    "        except RuntimeError as e:\n",
    "            if retry == max_retries - 1:\n",
    "                print(\"Error starting mission:\",e)\n",
    "                exit(1)\n",
    "            else:\n",
    "                time.sleep(2.5)\n",
    "\n",
    "    print(\"Waiting for the mission to start\", end=' ')\n",
    "    world_state = agent_host.getWorldState()\n",
    "    while not world_state.has_mission_begun:\n",
    "        \n",
    "        print(\".\", end=\"\")\n",
    "        time.sleep(0.1)\n",
    "        world_state = agent_host.getWorldState()\n",
    "        for error in world_state.errors:\n",
    "            print()   \n",
    "    print()\n",
    "    \n",
    "    print(\"Mission started \")\n",
    "    print(\"--------------------------------\")\n",
    "    # Run the program.\n",
    "    start_time = time.time()\n",
    "    cumulative_reward = agent.run(agent_host)\n",
    "    print('Reward obtained:%d' % cumulative_reward)\n",
    "    cumulative_rewards += [cumulative_reward]\n",
    "    timeTaken = (time.time() - start_time)\n",
    "    print(\"Total time trained:\", \"%s seconds\" % timeTaken )\n",
    "    print(\"Number of actions performed:\", agent.count_action())\n",
    "    result = [i, cumulative_reward, timeTaken, agent.count_action()]\n",
    "    results_df.append(result)\n",
    "    agent.resetcount_action()\n",
    "\n",
    "print()\n",
    "print(\"Done.\")\n",
    "print(\"Cumulative rewards for all %d runs:\" % num_repeats)\n",
    "print(cumulative_rewards)\n",
    "print(\"Average reward:\", sum(cumulative_rewards)/num_repeats)\n",
    "print(\"Total time used for 30 trials:\", \"%s seconds\" % (time.time() - start_time_all_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of attempt</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Time taken</th>\n",
       "      <th>Number of actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>300.498046</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>300.302921</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-108.0</td>\n",
       "      <td>300.698639</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-277.0</td>\n",
       "      <td>144.778111</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>172.476810</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-495.0</td>\n",
       "      <td>300.693258</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>530.0</td>\n",
       "      <td>300.740011</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>41.0</td>\n",
       "      <td>301.005393</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>44.0</td>\n",
       "      <td>300.721189</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>347.0</td>\n",
       "      <td>105.714471</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>158.293038</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-422.0</td>\n",
       "      <td>300.742409</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>-424.0</td>\n",
       "      <td>301.261486</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>89.0</td>\n",
       "      <td>300.818032</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>10184.0</td>\n",
       "      <td>228.941816</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>300.859931</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>96.959432</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>607.0</td>\n",
       "      <td>301.053883</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>-384.0</td>\n",
       "      <td>301.154988</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>116.0</td>\n",
       "      <td>300.622490</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>10436.0</td>\n",
       "      <td>51.492802</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>-375.0</td>\n",
       "      <td>300.755159</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>-138.0</td>\n",
       "      <td>109.686605</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-347.0</td>\n",
       "      <td>301.459495</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-346.0</td>\n",
       "      <td>300.811672</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>123.0</td>\n",
       "      <td>301.168653</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>10311.0</td>\n",
       "      <td>156.337314</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>-363.0</td>\n",
       "      <td>300.860407</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>301.483477</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>9863.0</td>\n",
       "      <td>115.542451</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of attempt   Reward  Time taken  Number of actions\n",
       "0                   0   -772.0  300.498046                773\n",
       "1                   1   -176.0  300.302921                676\n",
       "2                   2   -108.0  300.698639                609\n",
       "3                   3   -277.0  144.778111                277\n",
       "4                   4   1702.0  172.476810                299\n",
       "5                   5   -495.0  300.693258                495\n",
       "6                   6    530.0  300.740011                471\n",
       "7                   7     41.0  301.005393                460\n",
       "8                   8     44.0  300.721189                457\n",
       "9                   9    347.0  105.714471                154\n",
       "10                 10   -224.0  158.293038                225\n",
       "11                 11   -422.0  300.742409                422\n",
       "12                 12   -424.0  301.261486                425\n",
       "13                 13     89.0  300.818032                412\n",
       "14                 14  10184.0  228.941816                317\n",
       "15                 15     93.0  300.859931                408\n",
       "16                 16   1368.0   96.959432                132\n",
       "17                 17    607.0  301.053883                394\n",
       "18                 18   -384.0  301.154988                385\n",
       "19                 19    116.0  300.622490                384\n",
       "20                 20  10436.0   51.492802                 65\n",
       "21                 21   -375.0  300.755159                375\n",
       "22                 22   -138.0  109.686605                139\n",
       "23                 23   -347.0  301.459495                348\n",
       "24                 24   -346.0  300.811672                347\n",
       "25                 25    123.0  301.168653                378\n",
       "26                 26  10311.0  156.337314                190\n",
       "27                 27   -363.0  300.860407                364\n",
       "28                 28   1638.0  301.483477                363\n",
       "29                 29   9863.0  115.542451                138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "column = ['Number of attempt', 'Reward', 'Time taken', 'Number of actions']\n",
    "results_df = pd.DataFrame(results_df, columns = column)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epsilon value: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Current epsilon value:\", epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('simpleQ_09_M2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
